{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10_document_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1uq_7ar9puJJG8cKR8fRE2iwFCEpAq7DQ",
      "authorship_tag": "ABX9TyMEpO3mWAzn8swG7r/Ii1ev",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/courses/blob/master/10_document_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77taeHZLUaTm",
        "colab_type": "text"
      },
      "source": [
        "# 機械学習で文書分類を試みる\n",
        "\n",
        "* WikipediaからUSの男性俳優と女性俳優のページをクローリングして、spaCyで簡単な前処理を済ませてあるデータを使う。\n",
        "\n",
        " * 固有名詞、冠詞、前置詞、代名詞、副詞、数詞、接続詞は除去してある。\n",
        " * lemmatizationした結果を使っている。\n",
        " * \"actor\"と\"actress\"という単語は特別に除去してある。\n",
        "\n",
        "* 分析の目的1: 検証データでできるかぎりチューニングを行い、最後にテストデータでの分類性能を明らかにする。\n",
        "\n",
        "* 分析の目的2： 男性俳優と女性俳優のページを分類する際に、どのような単語が特に効いているかを調べる。\n",
        "\n",
        " * この調査によって、俳優に関する記述におけるジェンダー・ステレオタイプを明らかにできるか？"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qos6P0RsSsqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEMUit1zVZma",
        "colab_type": "text"
      },
      "source": [
        "### 1) データファイルを読み込む\n",
        "\n",
        "* データファイルは、あらかじめ自分のGoogle Driveの適当なフォルダに置いておく。\n",
        "\n",
        "* データファイルの各行には、女性俳優(1)か男性俳優(0)かを表すフラグ、俳優の名前、Wikipediaのページの本文が、この順に格納されている。\n",
        "\n",
        "* データファイルの各行に対してeval組み込み関数を適用すると、Pythonのリストに変換できるようなフォーマットで、ファイルに記録されている。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngsjTPa8TqgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = list()\n",
        "names = list()\n",
        "corpus = list()\n",
        "with open('drive/My Drive/data/us_actors_and_actresses.txt', 'r') as f:\n",
        "    for line in f:\n",
        "        flag, name, text = eval(line.strip())\n",
        "        y.append(int(flag))\n",
        "        names.append(name)\n",
        "        corpus.append(text)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48lbVvkseCqk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "cf16b526-6616-46f1-9448-1240b8510556"
      },
      "source": [
        "# corpusは、本文の文字列がたくさん入っているリスト。\n",
        "corpus[:10]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bear american bond appear guest television show feature film film production company call fellow bear convict manslaughter death aunt boyfriend finish serve year sentence',\n",
              " 'american film director',\n",
              " 'american film bear appear film remember role several film give era perform cast stereotypical role common film time boundless energy can see restrictive role master become know scared reaction comedy appear soundie musical film viewer will remember portrayal startled cook quizzical orderly frighten porter apprehensive watchman such film hold play lovable train conductor bug eye shriek ah lion attack rip seat pant shine pair shoe gag use previous short portrayal scene funny crew could contain laughter can hear final release memorable role hapless chef plumbing Will go utter bewilderment house sho go crazy able show range act talent role able raise laugh audience give suspicious sideway look kitchen appliance act footage would recycle more future comedy include film scene raincoat clothe inform guest dinner postpone account rain turn phrase use describe cancelling baseball game inclement weather make mark series receive featured billing several comedy produce valet scary situation react comic terror early 1950 appear several episode tv lodge member retire act die brain tumor age bury live see renew interest 1960 work stooge',\n",
              " 'american stage film television bear begin career age make feature film debut ticket taker television career play old man episode appear episode gunsmoke episode episode last appearance screen play die age',\n",
              " 'bear american silent film appear action film western film bear son father wish perform young child adolescence arrest infidelity complaint wife unknown enter film industry feature film could research career appear feature film known role husband outside married die age',\n",
              " 'bear american former child real estate broker commercial cast director entrepreneur known role bear bear classical musician parent mother renowned composer orchestra late 20th century guitar concerto her final contention father graduate clarinetist librarian play appear radio tv commercial voice over theater play role film year old perform declare hiatus act age kid go receive theatre urge travel found travel service arrange bind charter flight backpacker passion travel take country follow brief stint real estate film production commercial cast business representation few other venture sign autograph movie convention run photography business make sporadic appearance commercial play tv show adult acting appearance include sixth season episode series fawning fan play contestant bill former child star episode american game show themman appear british television morning show other child make additional 40th anniversary reunion appearance day appear tv version win money lose themman appear podcast episode record wife appear contestant return champion defeat third appearance contestant finish second place marry couple reside sister singer music therapist sister married voice voice director',\n",
              " 'american work television bear son geophysicist attend earn degree follow year stint rise rank plan study derail cast off play play close performance lead cast episode citation need appearance limit man follow regular soap opera search primetime recur role feature tv movie such eye take beautiful film appearance include title role ride edge will remember play play play other tv role include frasier caution murder Can hazardous married divorce marry daughter announce death day occur specify cause die heart attack',\n",
              " 'bear american stage film appear several dozen film character bear son first wife daughter prominent family citation need note variety performance weak willed strong character such father psychopathic killer good know performance ineffectual police chief father biker love interest film tough nonsense cop time antagonist film musical starring role write wind role television include role father lead role episode present last screen effort role rich patriarch self center greed riddled family wait benefactor die second wife stage son marry decade junior divorce cite abuse domestic cruelty divorce filing know committed suicide jump famous remain married fourth wife death citation need',\n",
              " 'pioneer african american martial artist member member focusse die cancer bear die raise graduating go attend graduate belief street provide dynamic education work firefighter achieve rank former jiujitsu practitioner learn member chairman hold position head coach key get karate recognize consider american martial art pioneer defeat many famous martial artist include tournament train consider contemporary 8th degree blackbelt induct feature various magazine include act movie star movie feature training youth documentary',\n",
              " 'writer producer director bear ambulance highway outskirt early training begin mentor late founder director choreographer educator join company member other notable teacher act act theater history voice costume make early training dancer include class short stay study perform meet go work numerous project include different tv appearance include guest star role different several commercial perform special receive nomination choreography appear nominate co star opening number original cast star have appear original production return company production play role other credit include play different time co star original australian cast die prostate cancer']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mB1KVAZ6YB3E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "566d5c85-6f00-442a-e46e-1c332f00e2aa"
      },
      "source": [
        "# yは男性俳優か女性俳優かを表す0/1のresponse。\n",
        "# namesは俳優の名前。\n",
        "y = np.array(y)\n",
        "names = np.array(names)\n",
        "print(names[:20])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['De%27Aundre_Bonds' 'James_McLaughlin_(actor)' 'Dudley_Dickerson'\n",
            " 'Charles_P._Thompson' 'Gus_Saville' 'Paris_Themmen' 'Peter_Haskell'\n",
            " 'Robert_Keith_(actor)' 'Thomas_Carroll_(martial_artist)'\n",
            " 'Matthew_Dickens' 'Nat_Benchley' 'Richard_Hunt_(puppeteer)'\n",
            " 'Thomas_McDonell' 'Paul_Smith_(American_actor,_born_1929)' 'Jim_Zulevic'\n",
            " 'Rob_Moran' 'Harry_Bannister' 'Shaun_Weiss' 'Peter_Sarsgaard'\n",
            " 'Palmer_Williams_Jr.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VR0Ew63dY-1I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7708ca67-4785-4c39-9c92-997e50af2664"
      },
      "source": [
        "# Nは全文書数。\n",
        "N = len(y)\n",
        "print('We have {:d} documents.'.format(N))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We have 19645 documents.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvlpBs-hGzML",
        "colab_type": "text"
      },
      "source": [
        "### 2) テストデータを分離"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqhGQYYQbDx-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ea278d60-4c3e-4fb5-d261-02668bba2922"
      },
      "source": [
        "# 訓練データとテストデータを分割するために、インデックスをランダムにシャッフルする。\n",
        "indices = np.arange(N)\n",
        "np.random.seed(123) # 乱数のシードを固定して再現性を持たせている。\n",
        "np.random.shuffle(indices)\n",
        "print(indices)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[12617 18144 17561 ... 15377 17730 15725]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuNIHWRbbMC6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a77d4f5c-7e4e-4d05-e5e5-dc68f6070658"
      },
      "source": [
        "# 手動で訓練データ8割、テストデータ2割に分割する。\n",
        "border = N * 8 // 10\n",
        "print('We have {:d} test documents.'.format(N - border))\n",
        "train_indices = indices[:border]\n",
        "test_indices = indices[border:]\n",
        "y_train = y[train_indices]\n",
        "y_test = y[test_indices]\n",
        "names_train = names[train_indices]\n",
        "names_test = names[test_indices]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We have 3929 test documents.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPZeCpZlesne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 本文のほうも、インデックスの同じ分割を使って、訓練データとテストデータに分割する。\n",
        "corpus_train = list()\n",
        "for i in train_indices:\n",
        "  corpus_train.append(corpus[i])\n",
        "corpus_test = list()\n",
        "for i in test_indices:\n",
        "  corpus_test.append(corpus[i])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZFZGWwte8fu",
        "colab_type": "text"
      },
      "source": [
        "（ここまでのtraining setとtest setへの分割は、変えないようにしてください。）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKg-InjbVh7r",
        "colab_type": "text"
      },
      "source": [
        "### 3) TF-IDFで各文書をベクトル化する\n",
        "\n",
        "* TF-IDFは単語列をベクトル化する方法のひとつ。\n",
        "\n",
        "* ベクトルの次元は語彙数となる。各Wikipediaのページがひとつのベクトルへ変換される。\n",
        "\n",
        "* TfidfVectorizerのパラメータをチューニングしても構わない\n",
        "\n",
        " * ここでTF-IDFの計算をするときにテストデータは使っていないので、ズルはしていない。\n",
        "\n",
        " * min_dfは、その数より少ない文書にしか出現しない単語を削除する、という意味のパラメータ。希少な単語を削除するために使う。\n",
        "\n",
        " * max_dfは、0から1の間の実数で指定すると、その割合より多い文書に出現する単語を削除する、という意味のパラメータ。ありふれた単語を削除するために使う。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHsek-uzTxi0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "38e0010d-34c0-4568-93f5-12d44d6c1592"
      },
      "source": [
        "vectorizer = TfidfVectorizer(stop_words='english', max_df=0.5, min_df=50)\n",
        "X_train = vectorizer.fit_transform(corpus_train)\n",
        "print('# X_train shape', X_train.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# X_train shape (15716, 3976)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUcTnazzT5Qm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 語彙を取得する。\n",
        "vocab = np.array(vectorizer.get_feature_names())"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e2QrURgT_gr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "c44d86e0-47ea-43a0-edc6-45ed60685a14"
      },
      "source": [
        "# 語彙の一部を見てみる（アルファベット順に並んでいるようだ）。\n",
        "print(vocab[1000:1010])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['define' 'defunct' 'defy' 'degree' 'delay' 'delete' 'delight' 'deliver'\n",
            " 'delivery' 'demand']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmRAzGE1W4af",
        "colab_type": "text"
      },
      "source": [
        "### 4) 5-fold 交差検証を使った、ロジスティック回帰による２値分類と評価\n",
        "\n",
        "* ロジスティック回帰のハイパーパラメータは、検証データでの分類性能ができるだけよくなるように、変更する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsjXWq7-EX2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "982vmj3KUH-5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "b179f6cd-e354-43b7-f2f0-3954e2af909f"
      },
      "source": [
        "# これは単純な実行例にすぎません。正則化も含めてチューニングしてください。\n",
        "# TfidfVectorizerのパラメータも併せてチューニングしていいです。\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
        "for train_index, valid_index in skf.split(X_train, y_train):\n",
        "  clf = LogisticRegression(max_iter=1000, solver='liblinear', random_state=123)\n",
        "  clf.fit(X_train[train_index], y_train[train_index])\n",
        "  print('validation mean accuracy: {}'.format(clf.score(X_train[valid_index], y_train[valid_index])))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validation mean accuracy: 0.8396946564885496\n",
            "validation mean accuracy: 0.8409163219853643\n",
            "validation mean accuracy: 0.8390073178491887\n",
            "validation mean accuracy: 0.8320076360165447\n",
            "validation mean accuracy: 0.8304167992363983\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnWcZHyJXFzR",
        "colab_type": "text"
      },
      "source": [
        "### 5) チューニングされたハイパーパラメータを使って、ロジスティック回帰の最終的な評価をおこなう\n",
        "\n",
        "* LogisticRegression() のカッコ内には、自分で見つけた最善のセッティングを書き込む。\n",
        "* 学習は、訓練データ全体（テストデータ以外の全体）を使っている。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQE3CxUdfZ7V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "698b8691-6a68-4825-ae69-1b6dfbc3e5e5"
      },
      "source": [
        "# 最も良かった設定を使って、訓練データ全体で再訓練\n",
        "clf = LogisticRegression(max_iter=1000, solver='liblinear', random_state=123)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# そして、最終的にテストデータで評価\n",
        "X_test = vectorizer.transform(corpus_test)\n",
        "print('test mean accuracy: {}'.format(clf.score(X_test, y_test)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test mean accuracy: 0.8274370068719776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdLcpwSwf3s3",
        "colab_type": "text"
      },
      "source": [
        "### 6) 5-fold 交差検証を使った、SVMによる２値分類と評価"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RoCT-f-f3Ow",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "579e8561-ed29-46ad-fcdb-3d1bdd8f3079"
      },
      "source": [
        "# これは単純な実行例にすぎません。ハイパーパラメータのチューニングもしてください。\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
        "for train_index, valid_index in skf.split(X_train, y_train):\n",
        "  svm = LinearSVC(C=0.1, max_iter=2000, random_state=123)\n",
        "  svm.fit(X_train[train_index], y_train[train_index])\n",
        "  print('validation mean accuracy: {}'.format(svm.score(X_train[valid_index], y_train[valid_index])))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validation mean accuracy: 0.8400127226463104\n",
            "validation mean accuracy: 0.8428253261215399\n",
            "validation mean accuracy: 0.8351893095768375\n",
            "validation mean accuracy: 0.8320076360165447\n",
            "validation mean accuracy: 0.8313713013044861\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7z1vXs4HfEV",
        "colab_type": "text"
      },
      "source": [
        "### 7) チューニングされたハイパーパラメータを使って、SVMの最終的な評価をおこなう"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guAY82oOHevE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "35cf3e12-8c34-436a-b8ec-fc4f589c385a"
      },
      "source": [
        "# 最も良かった設定を使って、訓練データ全体で再訓練\n",
        "svm = LinearSVC(C=0.1, max_iter=2000, random_state=123)\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# そして、最終的にテストデータで評価\n",
        "X_test = vectorizer.transform(corpus_test)\n",
        "print('test mean accuracy: {}'.format(svm.score(X_test, y_test)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test mean accuracy: 0.8271824891829982\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CtVT3KEXM7f",
        "colab_type": "text"
      },
      "source": [
        "### 8) 分類に効いている単語を調べる\n",
        "\n",
        "* 訓練データが最も数が多いので、訓練データの分類に最も効いている単語100語を調べる。\n",
        "\n",
        "* 下に示すのは、あくまで一つの方法にすぎない。他にどんな方法があるか調べて使ってみよう。\n",
        "\n",
        " * 下の手法の欠点は、男性俳優の文書に特徴的な単語と、女性俳優の文書に特徴的な単語とを、区別できない点である。\n",
        "\n",
        " * ヒント： 「svm important features」 あたりでググってみる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7An3q7JUK8G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "1ca6b1a8-8d5d-4263-d62f-681c74fccd98"
      },
      "source": [
        "# sklearnにあるrecursive feature eliminationという特徴量選択の手法を使ってみる。\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html\n",
        "\n",
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "rfe = RFE(estimator=clf, n_features_to_select=100, step=100)\n",
        "rfe.fit(X_train, y_train)\n",
        "ranking = rfe.ranking_\n",
        "print(vocab[ranking == 1])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['alumna' 'anime' 'announcer' 'attack' 'aunt' 'ballet' 'bar' 'baseball'\n",
            " 'basketball' 'beauty' 'birth' 'blonde' 'boxing' 'boy' 'breast' 'brother'\n",
            " 'cabaret' 'cheerleader' 'contest' 'cop' 'cover' 'cum' 'dancer' 'daughter'\n",
            " 'debut' 'detective' 'die' 'direct' 'director' 'discharge' 'draft'\n",
            " 'driver' 'enlist' 'father' 'female' 'fight' 'following' 'football'\n",
            " 'fraternity' 'gang' 'gangster' 'gay' 'girl' 'girlfriend' 'granddaughter'\n",
            " 'grandmother' 'guy' 'heroine' 'housekeeper' 'husband' 'joke' 'killer'\n",
            " 'lady' 'lesbian' 'magazine' 'maid' 'male' 'man' 'married' 'marry'\n",
            " 'matriarch' 'military' 'model' 'modeling' 'mom' 'mother' 'nephew' 'niece'\n",
            " 'nurse' 'née' 'officer' 'pageant' 'positive' 'pregnant' 'prostitute'\n",
            " 'queen' 'race' 'rapper' 'receptionist' 'regular' 'relocate' 'retire'\n",
            " 'screenplay' 'secretary' 'serve' 'singer' 'sister' 'soldier' 'son'\n",
            " 'soprano' 'sorority' 'stand' 'stuntman' 'team' 'villain' 'waiter'\n",
            " 'waitress' 'wife' 'witch' 'woman']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXuJHw6ZfTRO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "3ae2199f-e33e-4cc5-f99c-ccdd819f85cc"
      },
      "source": [
        "rfe = RFE(estimator=svm, n_features_to_select=100, step=100)\n",
        "rfe.fit(X_train, y_train)\n",
        "ranking = rfe.ranking_\n",
        "print(vocab[ranking == 1])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['acting' 'alumna' 'anchor' 'anime' 'announcer' 'attack' 'aunt' 'ballet'\n",
            " 'band' 'bar' 'baritone' 'baseball' 'basketball' 'beauty' 'birth' 'blonde'\n",
            " 'boy' 'breast' 'brother' 'cabaret' 'cheerleader' 'contest' 'cop' 'cover'\n",
            " 'dancer' 'daughter' 'debut' 'detective' 'direct' 'director' 'discharge'\n",
            " 'draft' 'driver' 'enlist' 'father' 'female' 'fight' 'following'\n",
            " 'football' 'fraternity' 'gang' 'gay' 'girl' 'girlfriend' 'granddaughter'\n",
            " 'grandmother' 'guitar' 'guy' 'heroine' 'housekeeper' 'husband' 'joke'\n",
            " 'killer' 'lady' 'lesbian' 'magazine' 'maid' 'male' 'man' 'married'\n",
            " 'marry' 'matriarch' 'military' 'model' 'modeling' 'mom' 'mother' 'nephew'\n",
            " 'niece' 'nurse' 'née' 'officer' 'pageant' 'pregnant' 'prostitute' 'queen'\n",
            " 'race' 'rapper' 'receptionist' 'relocate' 'retire' 'screenplay'\n",
            " 'secretary' 'serve' 'singer' 'sister' 'soldier' 'son' 'soprano'\n",
            " 'sorority' 'spokesman' 'stand' 'stuntman' 'team' 'villain' 'waiter'\n",
            " 'waitress' 'wife' 'witch' 'woman']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poCHDuUEhyXs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 18,
      "outputs": []
    }
  ]
}